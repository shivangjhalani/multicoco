{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.distributed\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"OpenGVLab/InternVL3-1B-Pretrained\", trust_remote_code=True, torch_dtype=torch.bfloat16, use_flash_attn=True, low_cpu_mem_usage=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"OpenGVLab/InternVL3-1B-Pretrained\", trust_remote_code=True, use_fast=False)\n"
      ],
      "metadata": {
        "id": "NwAa_OBRp0zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))\n",
        "print(dir(model)) # This will list all attributes and methods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USY30qe-zI0U",
        "outputId": "2ebd1f31-4913-4d6b-9131-8f8e0212bfd5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers_modules.OpenGVLab.InternVL3-1B-Pretrained.d3292416b2ecc894c0f4009a6dae424fbf164249.modeling_internvl_chat.InternVLChatModel'>\n",
            "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_assisted_decoding', '_auto_class', '_autoset_attn_implementation', '_backward_compatibility_gradient_checkpointing', '_backward_hooks', '_backward_pre_hooks', '_beam_search', '_beam_search_has_unfinished_sequences', '_buffers', '_cache_dependant_input_preparation', '_cache_dependant_input_preparation_exporting', '_call_impl', '_check_and_enable_flash_attn_2', '_check_and_enable_flash_attn_3', '_check_and_enable_flex_attn', '_check_and_enable_sdpa', '_checkpoint_conversion_mapping', '_compiled_call_impl', '_constrained_beam_search', '_contrastive_search', '_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_create_repo', '_device_mesh', '_dispatch_accelerate_model', '_dola_decoding', '_expand_inputs_for_generation', '_fix_state_dict_key_on_load', '_fix_state_dict_key_on_save', '_fix_state_dict_keys_on_save', '_flatten_beam_dim', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_from_config', '_gather_beams', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_cache', '_get_candidate_generator', '_get_files_timestamps', '_get_initial_cache_position', '_get_key_renaming_mapping', '_get_layer_device_map_for_cache_init', '_get_logits_processor', '_get_name', '_get_no_split_modules', '_get_resized_embeddings', '_get_resized_lm_head', '_get_running_beams_for_next_iteration', '_get_stopping_criteria', '_get_top_k_continuations', '_group_beam_search', '_has_unfinished_sequences', '_hf_peft_config_loaded', '_hook_rss_memory_post_forward', '_hook_rss_memory_pre_forward', '_init_added_embeddings_weights_with_mean', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', '_init_weights', '_initialize_missing_keys', '_initialize_weights', '_is_full_backward_hook', '_is_hf_initialized', '_is_stateful', '_keep_in_fp32_modules', '_keep_in_fp32_modules', '_keep_in_fp32_modules_strict', '_keep_in_fp32_modules_strict', '_keys_to_ignore_on_load_missing', '_keys_to_ignore_on_load_unexpected', '_keys_to_ignore_on_save', '_load_from_flax', '_load_from_state_dict', '_load_from_tf', '_load_pretrained_model', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_initialize_input_ids_for_generation', '_maybe_warn_non_full_backward_hook', '_merge_criteria_processor_list', '_modules', '_move_missing_keys_from_meta_to_cpu', '_named_members', '_no_split_modules', '_no_split_modules', '_non_persistent_buffers_set', '_parameters', '_pp_plan', '_prefill_chunking', '_prepare_attention_mask_for_generation', '_prepare_cache_for_generation', '_prepare_decoder_input_ids_for_generation', '_prepare_encoder_decoder_kwargs_for_generation', '_prepare_generated_length', '_prepare_generation_config', '_prepare_model_inputs', '_prepare_special_tokens', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_cache', '_replicate_for_data_parallel', '_resize_token_embeddings', '_sample', '_save_to_state_dict', '_set_default_torch_dtype', '_set_gradient_checkpointing', '_skip_keys_device_placement', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_supports_attention_backend', '_supports_cache_class', '_supports_default_dynamic_cache', '_supports_flash_attn_2', '_supports_flash_attn_3', '_supports_flex_attn', '_supports_logits_to_keep', '_supports_quantized_cache', '_supports_sdpa', '_supports_static_cache', '_temporary_reorder_cache', '_tie_encoder_decoder_weights', '_tie_or_clone_weights', '_tied_weights_keys', '_tp_plan', '_tp_size', '_tp_size', '_unflatten_beam_dim', '_update_finished_beams', '_update_model_kwargs_for_generation', '_upload_modified_files', '_valid_auto_compile_criteria', '_validate_assistant', '_validate_generated_length', '_validate_model_kwargs', '_version', '_wrapped_call_impl', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags', 'add_module', 'apply', 'base_model', 'base_model_prefix', 'batch_chat', 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'chat', 'children', 'compile', 'compute_transition_scores', 'config', 'config_class', 'conv_template', 'cpu', 'create_extended_attention_mask_for_decoder', 'cuda', 'delete_adapter', 'dequantize', 'device', 'disable_adapters', 'disable_input_require_grads', 'double', 'downsample_ratio', 'dtype', 'dummy_inputs', 'dump_patches', 'enable_adapters', 'enable_input_require_grads', 'estimate_tokens', 'eval', 'extra_repr', 'extract_feature', 'float', 'floating_point_ops', 'forward', 'framework', 'from_pretrained', 'generate', 'generate_batch', 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_compiled_call', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_init_context', 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter', 'get_parameter_or_buffer', 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'half', 'heal_tokens', 'img_context_token_id', 'init_continuous_batching', 'init_weights', 'initialize_weights', 'invert_attention_mask', 'ipu', 'is_backend_compatible', 'is_gradient_checkpointing', 'is_parallelizable', 'language_model', 'lm_head', 'load_adapter', 'load_custom_generate', 'load_state_dict', 'loss_function', 'loss_type', 'main_input_name', 'mlp1', 'model_tags', 'modules', 'mtia', 'name_or_path', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_image_token', 'num_parameters', 'parameters', 'patch_size', 'pixel_shuffle', 'post_init', 'prepare_inputs_for_generation', 'prune_heads', 'ps_version', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'save_pretrained', 'select_layer', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'set_submodule', 'share_memory', 'smart_apply', 'state_dict', 'supports_gradient_checkpointing', 'supports_pp_plan', 'supports_tp_plan', 'system_message', 'template', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'tp_size', 'train', 'training', 'type', 'vision_model', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FH61-EPp8Zq",
        "outputId": "0dca1ee4-b6f3-4034-9bb9-d252f5f15996"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InternVLChatModel(\n",
            "  (vision_model): InternVisionModel(\n",
            "    (embeddings): InternVisionEmbeddings(\n",
            "      (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
            "    )\n",
            "    (encoder): InternVisionEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-23): 24 x InternVisionEncoderLayer(\n",
            "          (attn): InternAttention(\n",
            "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (mlp): InternMLP(\n",
            "            (act): GELUActivation()\n",
            "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          )\n",
            "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop_path1): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (language_model): Qwen2ForCausalLM(\n",
            "    (model): Qwen2Model(\n",
            "      (embed_tokens): Embedding(151674, 896)\n",
            "      (layers): ModuleList(\n",
            "        (0-23): 24 x Qwen2DecoderLayer(\n",
            "          (self_attn): Qwen2Attention(\n",
            "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
            "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
            "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
            "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
            "          )\n",
            "          (mlp): Qwen2MLP(\n",
            "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
            "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
            "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
            "            (act_fn): SiLU()\n",
            "          )\n",
            "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
            "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
            "        )\n",
            "      )\n",
            "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
            "      (rotary_emb): Qwen2RotaryEmbedding()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=896, out_features=151674, bias=False)\n",
            "  )\n",
            "  (mlp1): Sequential(\n",
            "    (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=4096, out_features=896, bias=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=896, out_features=896, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9R6CKMRzON6",
        "outputId": "85e0b04c-d9cc-49fb-dd6c-5dccf723fdd8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InternVLChatConfig {\n",
            "  \"architectures\": [\n",
            "    \"InternVLChatModel\"\n",
            "  ],\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_internvl_chat.InternVLChatConfig\",\n",
            "    \"AutoModel\": \"modeling_internvl_chat.InternVLChatModel\",\n",
            "    \"AutoModelForCausalLM\": \"modeling_internvl_chat.InternVLChatModel\"\n",
            "  },\n",
            "  \"downsample_ratio\": 0.5,\n",
            "  \"dynamic_image_size\": true,\n",
            "  \"force_image_size\": 448,\n",
            "  \"image_fold\": null,\n",
            "  \"llm_config\": {\n",
            "    \"_name_or_path\": \"./pretrained/Qwen2.5-32B-Instruct\",\n",
            "    \"architectures\": [\n",
            "      \"Qwen2ForCausalLM\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"eos_token_id\": 151643,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 896,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4864,\n",
            "    \"layer_types\": [\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\",\n",
            "      \"full_attention\"\n",
            "    ],\n",
            "    \"max_position_embeddings\": 32768,\n",
            "    \"max_window_layers\": 70,\n",
            "    \"model_type\": \"qwen2\",\n",
            "    \"moe_config\": null,\n",
            "    \"num_attention_heads\": 14,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": {\n",
            "      \"factor\": 2.0,\n",
            "      \"rope_type\": \"dynamic\",\n",
            "      \"type\": \"dynamic\"\n",
            "    },\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sliding_window\": null,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"vocab_size\": 151674\n",
            "  },\n",
            "  \"max_dynamic_patch\": 12,\n",
            "  \"min_dynamic_patch\": 1,\n",
            "  \"model_type\": \"internvl_chat\",\n",
            "  \"output_attentions\": false,\n",
            "  \"pad2square\": false,\n",
            "  \"ps_version\": \"v2\",\n",
            "  \"select_layer\": -1,\n",
            "  \"template\": \"internvl2_5\",\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_backbone_lora\": 0,\n",
            "  \"use_llm_lora\": 0,\n",
            "  \"use_thumbnail\": true,\n",
            "  \"vision_config\": {\n",
            "    \"_name_or_path\": \"OpenGVLab/InternViT-6B-448px-V1-5\",\n",
            "    \"architectures\": [\n",
            "      \"InternVisionModel\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"auto_map\": {\n",
            "      \"AutoConfig\": \"configuration_intern_vit.InternVisionConfig\",\n",
            "      \"AutoModel\": \"modeling_intern_vit.InternVisionModel\"\n",
            "    },\n",
            "    \"capacity_factor\": 1.2,\n",
            "    \"drop_path_rate\": 0.0,\n",
            "    \"dropout\": 0.0,\n",
            "    \"eval_capacity_factor\": 1.4,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_size\": 1024,\n",
            "    \"image_size\": 448,\n",
            "    \"initializer_factor\": 0.1,\n",
            "    \"initializer_range\": 1e-10,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"laux_allreduce\": \"all_nodes\",\n",
            "    \"layer_norm_eps\": 1e-06,\n",
            "    \"model_type\": \"intern_vit_6b\",\n",
            "    \"moe_coeff_ratio\": 0.5,\n",
            "    \"moe_intermediate_size\": 768,\n",
            "    \"moe_output_scale\": 4.0,\n",
            "    \"noisy_gate_policy\": \"RSample_before\",\n",
            "    \"norm_type\": \"layer_norm\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_channels\": 3,\n",
            "    \"num_experts\": 8,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_routed_experts\": 4,\n",
            "    \"num_shared_experts\": 4,\n",
            "    \"patch_size\": 14,\n",
            "    \"qk_normalization\": false,\n",
            "    \"qkv_bias\": true,\n",
            "    \"shared_expert_intermediate_size\": 3072,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_flash_attn\": false,\n",
            "    \"use_moe\": false,\n",
            "    \"use_residual\": true,\n",
            "    \"use_rts\": false,\n",
            "    \"use_weighted_residual\": false\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)\n",
        "# print(tokenizer.pad_token)\n",
        "# print(tokenizer.padding_side)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez5yJgPUyHzZ",
        "outputId": "1cee65e1-7992-4ed9-ddbc-25e6ee51ead3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen2Tokenizer(name_or_path='OpenGVLab/InternVL3-1B-Pretrained', vocab_size=151643, model_max_length=1000000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151665: AddedToken(\"<img>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151666: AddedToken(\"</img>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151667: AddedToken(\"<IMG_CONTEXT>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151668: AddedToken(\"<quad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151669: AddedToken(\"</quad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151670: AddedToken(\"<ref>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151671: AddedToken(\"</ref>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151672: AddedToken(\"<box>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151673: AddedToken(\"</box>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.padding_side = \"right\" # Is already right\n",
        "tokenizer.add_tokens(\"<|start-latent|>\")\n",
        "tokenizer.add_tokens(\"<|end-latent|>\")\n",
        "tokenizer.add_tokens(\"<|latent|>\")\n",
        "latent_id = tokenizer.convert_tokens_to_ids(\"<|latent|>\")\n",
        "start_id = tokenizer.convert_tokens_to_ids(\"<|start-latent|>\")\n",
        "end_id = tokenizer.convert_tokens_to_ids(\"<|end-latent|>\")\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "zrLshRHgqf0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d494913b-ea84-4873-c7d6-37b4e39d99f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen2Tokenizer(name_or_path='OpenGVLab/InternVL3-1B-Pretrained', vocab_size=151643, model_max_length=1000000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151665: AddedToken(\"<img>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151666: AddedToken(\"</img>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151667: AddedToken(\"<IMG_CONTEXT>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151668: AddedToken(\"<quad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151669: AddedToken(\"</quad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151670: AddedToken(\"<ref>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151671: AddedToken(\"</ref>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151672: AddedToken(\"<box>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151673: AddedToken(\"</box>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151674: AddedToken(\"<|start-latent|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
            "\t151675: AddedToken(\"<|end-latent|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
            "\t151676: AddedToken(\"<|latent|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P86PlOG8rCtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dbe8f1d"
      },
      "source": [
        "print(model.vision_model)\n",
        "print(model.language_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}